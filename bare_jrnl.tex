\documentclass[journal]{IEEEtran}
\usepackage{booktabs}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{svg}
\usepackage[style=ieee, backend=biber]{biblatex}
\addbibresource{main.bib}
\renewcommand*{\bibfont}{\footnotesize}

\ifCLASSINFOpdf
  \usepackage{graphicx}
\else
\fi

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}


% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Intelligent Systems 2 Group Assessment }

\author{Group 9: Harry Kelly, Sal Ahmed, Ayyesha Shahzad, Jakub Popiolek, Joe Sanders, Clara Hohenlohe}

% The paper headers
\markboth{INT2 Group Project - Group 9}
%Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2015}%
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for IEEE Journals}

% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
Our task was to train a machine learning model to classify images into predefined categories. The model is a neural network classifier, and has been trained and tested on the CIFAR-10 dataset. To implement our model into Python we used PyTorch 1.8 and after running our model at 7000 epochs we achieved an accuracy of 91.49\%.
\end{abstract}

\IEEEpeerreviewmaketitle

\section{Introduction}

\IEEEPARstart{O}{ur} task was to create a convolutional neural network that could perform image classification on 2D images. The network must be trained using the CIFAR-10 dataset and must take no longer than 24 hours to train.

In 1989, Yann LeCun proposed one of the earliest convolutional neural networks, the LeNet \cite{LeCun1989}. Inspired by LeCun’s CNN design, computer scientist Alex Krizhevsky and his collaborators designed the CNN architecture, AlexNet \cite{AlexNetArticle}. This is now regarded as a leading architecture for any object-detection task due to the new techniques that AlexNet introduced: using ReLU instead of the Tanh function (the then standard), overlapping the ‘pools’ of outputs of neighbouring groups of neurons, and training the model using multiple GPUs \cite{tdsAlexNet}. 

Image classification is an important machine learning problem, as innovations here can lead to advancements in many technologies, driverless car technology, as accurately identifying different objects on the road is crucial for ensuring a safe journey \cite{ImageRecognitionApp}.

\section{Method}
Our architecture begins with data augmentation, utilising the RandomHorizontalFlip and RandomCrop transformations on the 64 images in each batch. This increases the data available for the model to train on \cite{dataAug}; a cat facing towards the right is distinct to a cat facing towards the left. This is because the convolutional neural network uses 3x3 filters to detect distinct features such as left or right edges of various lengths.

The network includes six convolutional layers, combining low level features such as lines to make more complex shapes such as animal faces. The output of each of these layers is passed to a ReLU activation function which provides non-linearity - without a non-linear activation function the CNN would have limited linear capabilities. ReLU is used instead of alternatives such as sigmoid or tanh due to its ability to deactivate neurons if the input is less than zero, allowing for more complex learning.

Next, a Max-Pooling function is applied to the output ‘feature map’ three times in the network. This extracts important learned features from the convolutional layers and returns a smaller feature map with only the features and their relation to one another, it is not concerned with the object's position and thus can better generalise to other data. This information is flattened with Tensor.view() then passed forward.

The network also includes three Batch Normalisations that negate the effect of internal covariate shift, standardising the outputs of the previous layers into a Gaussian distribution \cite{ioffe2015batch}. This stabilises the inputs for each layer during training - their distribution would otherwise fluctuate, which would lead to a higher overfitting error. Dropouts help generalise the data, randomly zeroing neurons to reduce other neurons' dependence on them.

Finally, three fully-connected (linear) layers map their neurons to activations from previous layers, combining the features learnt in those layers to classify images in the last fully-connected layer \cite{matlab}, with output dimensions (1 x 10) from the input dimensions (32 x 32 x 3). This means that from the 32x32 training images with 3 channels (RGB), a final layer has been produced with a number of neurons equal to the number of possible classes. Each neuron in that layer is computed as the weighted sum of the previous neurons plus an additional bias to denote how likely a neuron is to be active (this is computed at each fully-connected layer):

% inserts equation
\begin{equation*}
    A = W^Tx + W_{0}
\end{equation*}

The neuron with the largest activation in this final layer corresponds to the predicted image class, which results in a one-hot encoded row in the tensor. This is repeated for each of the sixty-four items in the batch, hence the (64 x 10) final output dimensions.

The loss for each prediction is calculated using the  Cross Entropy Loss function for multiple classes, otherwise known as Negative Log Likelihood Loss:
% inserts equation
\begin{equation*}
    L_{NLL}(g, y) = -(y log(g) + (1 - y) log(1 - g))
\end{equation*}
Where g is the prediction and y is the correct label. This loss is calculated and the necessary adjustments to the weights are propagated backwards and averaged over the training set. The resulting vector of averaged adjustments to each weight is proportional to the negative gradient of the cost function \cite{3b1b}. This information is then used to calculate the minimum cost using Stochastic Gradient Descent as the optimiser. SGD is used instead of Gradient Descent as it can be performed over mini-batches to reduce computation time. Furthermore, it arguably leads to a more accurate model when performed over enough epochs when compared to alternatives such as ADAM \cite{cifar10}.


\section{Network Architecture} 
Our network architecture is shown in Figure~\ref{diagram}
\begin{figure}[!h]
  \centering
  %\includesvg{Network_Diagram.svg}
  \includesvg[width=155pt]{Network_Diagram.svg}
  \caption{Network Architecture Diagram, showing input dimensions}
  \label{diagram}
\end{figure}


\section{Results and Evaluation}
By training our neural network over 7000 epochs (17 hours), we managed to produce a 8.51\% test error for the given dataset, which our team decided was satisfactory. Running the code for 1000 epochs (2.5 hours) produced a test error of 8.65\%, only 0.15\% better than the previous result, leading us to believe that we have reached a plateau value and running the code for longer without additional changes is not necessary. The classification test error was calculated by checking the percentage of incorrect guesses from all 10000 test images.

\begin{table}[!h]
\centering
\caption{Table of Parameters}
\label{table:1}
\begin{tabular}{@{}llll@{}}
\toprule
\multirow{2}{*}{Layer} & \multicolumn{2}{l}{Channels} & \multirow{2}{*}{Other Parameters} \\ \cmidrule(lr){2-3}
              & In   & Out  &                              \\ \midrule
Convolution 1 & 3    & 32   & Kernel Size = 3, Padding = 1 \\
Batch 1       & 32   & 32   &                              \\
Convolution 2 & 32   & 64   & Kernel Size = 3, Padding = 1 \\ \midrule
Convolution 3 & 64   & 128  & Kernel Size = 3, Padding = 1 \\
Batch 2       & 128  & 128  &                              \\
Convolution 4 & 128  & 128  & Kernel Size = 3, Padding = 1 \\
Dropout 2     &      &      & P = 0.05                     \\ \midrule
Convolution 5 & 128  & 256  & Kernel Size = 3, Padding = 1 \\
Batch 3       & 256  & 256  &                              \\
Convolution 6 & 256  & 256  & Kernel Size = 3, Padding = 1 \\ \midrule
Dropout 1     &      &      & P = 0.1                      \\
Linear 1      & 4096 & 1024 &                              \\
Linear 2      & 1024 & 512  &                              \\
Linear 3      & 512  & 10   &                              \\ \bottomrule
\end{tabular}
\end{table}

Our main evaluation metric was said test error. It gave us an easy way to see the impact of changes. Due to the large amount of data, the value should be reliable, producing only small fluctuations between executions of the same code. We also looked at the loss value and how much it decreased with each epoch. 

While we started out with SGD, we experimented with using another optimizer, ADAM, instead. It worked very fast, producing $\approx$80\% accuracy within only 10 epochs. While we were impressed with ADAM achieving that number in such a small time, we realised that it also meant a quick plateau and not much improvement from there, as 80 epochs only improved our accuracy by $\approx$1\%. As we were not under time pressure, having 24h to run our code, we went back to SGD as that could produce a higher number, albeit taking more epochs to train. We also experimented with batch size, trying out 32, 64 and 128, settling on 64. While 128 sped up the computation of each epoch, 64 led to a slight increase in accuracy. Testing batch size 32 slowed the process with no further improvement. With convolutional layers, we started off with two, but ended up using six as that seemed to produce the best results. We also used padding on these layers.

As only one member of our team owns a GPU capable of running the code at an adequate pace (Nvidia RTX 3060 TI), we decided on using Google Colab as an environment. This allows every member to write and execute the code. We used GitHub for version control. 

\section{Conclusion and Further Work}
Our model performed well, with 91.49\% accuracy over 7000 epochs. Consequently, we believe our architecture is a good choice, but can still be further improved. We were able to create a good model quickly using the Adam optimiser, but struggled to improve our model until we reverted to SGD, which allow to improve our model. We had attempted to use a scheduler to adjust the learning rate, however after encountering some trouble opted not to. In the future we would like to correctly implement the use of a scheduler to take advantage of the benefits of changing the learning rate. We would also like to look into the AdaBound optimiser, which claims to have the benefits of both SGD and Adam, which could help us improve our model further.


\ifCLASSOPTIONcaptionsoff
  \newpage
\fi

\printbibliography

\end{document}


